public:: true 

#Public page automatically published

- # The traditional ML concept:
	- In machine learning, bias and variance represent a trade-off in a model's ability to generalize.
		- **High Bias:** Model is too simple, underfits data,  generalizes poorly.
		- **High Variance:**  Model is overly complex, overfits data, generalizes poorly
		- **Goal:** Find the ideal balance for accurate predictions on new data.
- ## Bias in Large Language Models (LLMs):
	- Takes on an additional and critical dimension. These models aren't just fitting curves; they're processing  the complexities and prejudices within massive amounts of human language data.
	- Even a statistically "accurate" LLM can reflect the worst of human biases hidden within our own messy, real-world language.
- **How societal bias seeps into LLMs:**
	- **Training data:** If real-world text samples contain racial stereotypes, sexist viewpoints, etc., the LLM can internalize these.
	- **Associations:** Models learn by statistical patterns. "If X then often Y" can replicate prejudices even if 'X' is a demographic and 'Y' is a negative or limiting assumption.
	- [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/abs/1607.06520)
- **Consequences of LLM bias:**
	- * **Perpetuation of stereotypes:** When biased language is generated, it amplifies harmful misconceptions that already exist in society, harming marginalized groups.
	- * **Algorithmic decision-making:** If LLMs are used in areas like hiring or risk assessment, bias can translate into real-world discrimination.
- **Addressing the problem:**
	- * **It's not about elimination:** Creating perfectly unbiased language models is unlikely.  The focus is on:
	- * **Identifying bias:** Thorough testing across diverse demographics is crucial.
	- * **Mitigation:** De-biasing techniques, more representative training data, etc., can reduce harmful outputs.
	- * **Responsible use:** Recognizing the potential for bias means we, as users, must stay critical, especially in sensitive areas.
	- [twitter link to the render loading below](https://twitter.com/bindureddy/status/1760343060985340368)
	  {{twitter https://twitter.com/bindureddy/status/1760343060985340368}}
		- ## Bias in images
			- Bias is really hard, and the current tools are blunt.
			- [twitter link to the render loading below](https://twitter.com/IMAO_/status/1760093853430710557)
			  {{twitter https://twitter.com/IMAO_/status/1760093853430710557}}
				- # Research Papers
					- **Homogenization of Cultural Preferences**: Budzinski and Pannicke (2017) analyzed voting data from the Eurovision Song Contest to test the hypothesis of homogenization of cultural preferences due to digitalization. Contrary to the theory, their findings do not support a trend towards homogenization. Instead, some indicators suggest weak trends of deconcentration in voting behavior, indicating diverse preferences [(Budzinski & Pannicke, 2017)](https://consensus.app/papers/preferences-music-converge-across-countries-empirical-budzinski/4baf26344e6c5f62a89851a45f2e8ee9/?utm_source=chatgpt).
					- **Consumer Behavior Heterogeneity**: Mooij and Hofstede (2002) argue that converging technology and income levels will not lead to a homogenization of consumer behavior. Cultural differences will likely cause consumer behavior to become more heterogeneous, emphasizing the importance of understanding national cultural values and their impact on behavior [(Mooij & Hofstede, 2002)](https://consensus.app/papers/convergence-divergence-consumer-behavior-implications-mooij/0fdf7549d4ed5a10b4e67469115c83e6/?utm_source=chatgpt).
					- **Digital Culture and Education**: Kultaieva (2020) discusses the impact of digital culture on communication and self-recognition in post-industrial societies. The paper highlights the changes in communication forms within digital culture, emphasizing visual culture over traditional writing culture [(Kultaieva, 2020)](https://consensus.app/papers/homo-digitalis-digital-culture-digital-education-kultaieva/f44183f43b2c5fb79e12fbea03e1804d/?utm_source=chatgpt).
					- **Algorithmic Consumer Culture**: Airoldi and Rokka (2022) conceptualize algorithmic consumer culture, exploring how the opacity, authority, non-neutrality, and recursivity of algorithms affect consumer culture at various levels. This provides insights into how digitalization and big data surveillance practices shape consumption patterns [(Airoldi & Rokka, 2022)](https://consensus.app/papers/consumer-culture-airoldi/d2cfefc419485f6286ce2e4ca9d165bf/?utm_source=chatgpt).
					- **Cultural Homogenization and Technology**: Fairweather and Rogerson (2003) discuss the implications of global cultural homogenization in a technologically dependent world, examining how information and communication technologies contribute to this process [(Fairweather & Rogerson, 2003)](https://consensus.app/papers/problems-homogenisation-technologically-world-fairweather/906e1d758b775c2a963acc4d52438a94/?utm_source=chatgpt).
					- **Cultural Consequences of Globalization**: Holton (2000) analyzes cultural consequences of globalization, discussing homogenization, polarization, and hybridization theses. The study suggests that global culture is not becoming entirely standardized around Western patterns, highlighting cultural alternatives and resistance [(Holton, 2000)](https://consensus.app/papers/globalizations-cultural-consequences-holton/ecdfbc4c728d55378e11dd54e01fe806/?utm_source=chatgpt).
					- [Filterworld: How Algorithms Flattened Culture: Chayka, Kyle: 9780385548281: Amazon.com: Books](https://www.amazon.com/Filterworld-How-Algorithms-Flattened-Culture/dp/0385548281)
	-
- ## Scrapbook
	- Model Evaluation Techniques
		- Basic Parameters
			- Bias & Variance
		- Measures to understand if our model is too simplistic (high bias) or too complex (high variance).
			- [Bias-Variance in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)
			- Overfitting & Underfitting
		- Indicators that our model is either too closely tailored to the training data or too general.
			- [Regularization in TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers)
			- Holdout Method (Train / Test Split)
		- A basic approach to split the dataset into training and testing sets.
			- [Train/Test Split in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
			- Confidence Intervals
		- Statistical range that expresses where the true model performance metric lies with a certain probability.
			- [StatsModels for Confidence Intervals](https://www.statsmodels.org/stable/index.html)
		- Resampling Methods
			- Repeated Holdout
		- Running holdout method multiple times to get a better estimate of model performance.
			- [RepeatedKFold in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html)
			- Empirical Confidence Intervals
		- Confidence intervals derived from the resampling distribution of a performance metric.
			- [Bootstrapping in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html)
		- Cross-validation
			- Hyperparameters Tuning
		- The process of finding the optimal set of hyperparameters for a learning algorithm.
			- [GridSearchCV in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)
			- Model Selection
		- Choosing the best model from a set of candidate models.
			- [Model Selection in scikit-learn](https://scikit-learn.org/stable/model_selection.html)
			- Algorithm Selection
		- Determining which learning algorithm to use for a given problem.
			- [MLflow for Experiment Tracking](https://mlflow.org/)
		- Statistical Tests
			- Model Comparison
		- Statistical tests to compare the performance of two models.
			- [Paired t-tests in SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html)
			- Algorithm Comparison]- Comparing different algorithms to find which performs best on the data.
			- [Friedman test in SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.friedmanchisquare.html)
		- Evaluation Metrics
			- Metrics to quantify the performance of the model.
				- [Evaluation Metrics in scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html)
	-