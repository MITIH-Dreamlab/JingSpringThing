public:: true

- #Public page automatically published
- ## OpenAi Sora
  id:: 661d5f76-bd9c-493d-afc1-efcec299ed24
	- proprietary
	- OpenAI's Sora model represents a notable advancement in AI video generation. It demonstrates the ability to generate videos up to one minute in 1080p resolution and produce high-resolution images. Sora's flexibility in handling various aspect ratios and resolutions indicates its adaptability in content creation. Its development leverages insights from prior research, including Vision Transformers and advanced training methodologies.
	- {{video https://www.youtube.com/watch?v=GqsCMPWaYac}}
	-
	- **Introduction to Sora**
		- A groundbreaking AI video generation model by OpenAI, Sora is designed to transform text instructions into realistic and imaginative video scenes, marking a significant advancement in creative AI technologies.
	- **Technical Overview**
		- **Advanced Diffusion Model**
			- Employs a sophisticated diffusion process that starts from static noise and incrementally refines to generate high-resolution videos, showcasing an unparalleled leap in video realism and complexity.
		- **Transformer Architecture**
			- Leverages the Transformer model's capabilities for deep understanding and generation of content, adapted here to interpret and create complex visual narratives, ensuring dynamic and coherent video storytelling.
			- [twitter link to the render loading below](https://twitter.com/sainingxie/status/1758433676105310543)
			  {{twitter https://twitter.com/sainingxie/status/1758433676105310543}}
			- [twitter link to the render loading below](https://twitter.com/thatguybg/status/1759935959792312461)
			  {{twitter https://twitter.com/thatguybg/status/1759935959792312461}}
			- **Patch-Based Data Representation**
				- Innovatively represents videos and images as collections of smaller data units, akin to language model tokens, enabling precise and granular control over video generation and editing.
	- {{twitter https://twitter.com/drjimfan/status/1758355737066299692?s=46}}
	- **Creative and Professional Applications**
		- Opens up endless possibilities for filmmakers, advertisers, educators, and content creators to produce cinema-quality visuals, educational materials, and immersive experiences effortlessly.
	- **Democratization of Video Production**
		- Simplifies the video creation process, enabling individuals and small teams to produce content that rivals big studio outputs.
	- **Enhancement of Creative Expression**
		- Allows creators to bring intricate visions and stories to life through simple text prompts, expanding visual storytelling horizons.
	- **Technical Insights**
		- Designed to scale language model capabilities to visual data, converting videos into patches for efficient processing and diverse video/image handling.
		- Features a video compression network for temporal and spatial video compression, operating within a [[latent space]].
		- Uses a diffusion transformer architecture, effectively scaling video generation and improving sample quality with increased compute.
	- **Innovative Features**
		- Works with videos at native sizes to offer sampling flexibility and improve composition and framing.
		- Leverages descriptive captioning technique, enhancing video fidelity and quality from text prompts.
		- Can animate still images and extend videos, including seamless interpolation between two videos, showcasing versatility.
	- **Emerging Capabilities**
		- Exhibits capabilities like 3D consistency, long-range coherence, object permanence, and world interaction simulation.
		- Suggests potential as a tool for simulating physical and digital environments, aiding in the development of capable simulators.
		- Videos can serve as a basis for constructing detailed 3D scenes using techniques like Neural Radiance Fields (NeRFs), potentially revolutionizing 3D content creation and interaction.
		- Rapid prototyping and realization of 3D environments and narratives enhance VR and AR immersion and interactivity.
		- Enables generation of characters, objects, and worlds through text and voice prompts, making 3D content creation more intuitive and accessible.
		- Already being used to create 360 spherical video.
	- **Research and Discussion**
		- [Video generation models as world simulators (openai.com)](https://openai.com/research/video-generation-models-as-world-simulators) research paper highlights Sora's technical foundation and its role in simulating the physical world.
		- Discussions emphasize Sora's potential in democratizing video creation and the need for granular output control for artistic purposes.
- ## Google Veo
  id:: 664465de-5bd3-4169-a90b-c03f117bef04
	- [Google DeepMind on X: "Introducing Veo: our most capable generative video model. ðŸŽ¥ It can create high-quality, 1080p clips that can go beyond 60 seconds. From photorealism to surrealism and animation, it can tackle a range of cinematic styles. ðŸ§µ #GoogleIO https://t.co/6zEuYRAHpH" / X (twitter.com)](https://twitter.com/GoogleDeepMind/status/1790435824598716704)
	- {{twitter https://twitter.com/GoogleDeepMind/status/1790435824598716704}}