public:: true

	- Original chat
	- While I was doing my masters in ML in 2020 the term for [[safety and alignment]] was simply bias. Bias is a huge and potentially unsolvable problem at scale. You can actually revert to using bias and very quickly get to a terrifying outcome if you simply cast AI as a near ubiquitous data helper, that carries racism and sexism very deep inside. This already is an existential risk to people suffering wrongful prosecution. What Hinton clearly means by existential risk is risk to the rich.
	- AI already is capable of out producing humans on data, and that is also already a catastrophe for human data online, because of signal to noise. No mitigation possible.
	- The FOOM risk is unknown, likely unknowable and POSSIBLY not zero.
	- The branching tree of outcomes has something like 90 net negative end points for humans and only one positive, and that turns out to be "the culture"
	  We are doing virtually nothing to address, mitigate, plan for, or even discuss these things, outside of a few crackpot self help actuators. Also see Transhumanism, Singularitarians, Crypto-Anarchists, Biohackers/Grinders, Effective Altruists, Technotopians, AI Optimists/Pessimists, Quantified Self Movement, Affective Accelerationism. Many of whom are incredibly wealthy and influential nut jobs.
	- [The Rise of Techno-authoritarianism
	- The Atlantic](https://www.theatlantic.com/magazine/archive/2024/03/facebook-meta-silicon-valley-politics/677168/)
	- In return AI promises to be able to do our "drudge work": also see, sitting down type jobs.
	- Add in [[Cyber security and Cryptography]], [[Bio Terror]] , mass 3D printing of weapons, [[Cyber Security and Military]] fully autonomous killing machines, [[Death of the Internet]] and gated AI controlled communities, and you have pretty much nothing but dystopia all the way down.
	- Do I think about a dozen luny men should be in charge of the pack of stick on adjustments that align AI? Something they all agree they have no plan to actuate? GOD NO.
	- Am I determined not to be asleep at the wheel? Depends if I can even find a wheel tbh.
	-
- Statistical engines which are very difficult not to anthropomorphise.
	- These incredibly profitable stacks are the product of surveillance capitalism.
	- Check meredith whittaker from signal for grounded risks. Regulation from below, and part of the [[Social contract and jobs]].
	- They didn't make these for the public good, they made them for profit, and these products entrench the surveillance capitalism abuse.
	- It is not being democratically or equitably distributed.
	- Natasha tiku at the post.
	- Main risk is actually the concentration of power in a few huge corporations
	- AI cultural imperialism. This is countered by national models like Falcon, Alibaba, Mistral. Interestingly the Economist brands this [the era of AI nationalism](https://www.economist.com/business/2024/01/01/welcome-to-the-era-of-ai-nationalism)
	-
- Updated by gpt
	- **Bias in AI:** Represents a critical and stubborn issue. At scale, unchecked AI can perpetuate racism and sexism, leading to deeply entrenched societal problems. Vigilance and continuous improvement in AI ethics are required to prevent these outcomes.
	- **Data Overwhelm:** AI's ability to process information far exceeds human capacity, creating a deluge of data that threatens the quality and integrity of human knowledge. This "signal-to-noise" problem is not just an inconvenience; it's a critical challenge for information validity in the digital age.
	- **FOOM Risk:** The fear of rapid, uncontrollable advancements in AI (FOOM) presents a scenario of existential uncertainty. While its probability is debated, the potential consequences are so severe that they demand serious attention and preemptive planning.
	- **Dystopian Outcomes:** Considering the branching tree of potential futures, the overwhelming majority appear to lead to negative outcomes for humanity. This isn't a mere pessimistic view but a call to steer technology towards a singular, positive cultural and societal impact.
	- **Inaction and Fragmentation:** The current landscape of AI governance is a tapestry of competing ideologies and interests, from Transhumanists to Crypto-Anarchists. The lack of coherent and concerted action is alarming, given the stakes involved.
	- **The Automation Promise:** While AI promises to relieve us from drudgery, there's a thin line between utopian efficiency and a dystopian replacement of human roles. Ensuring AI serves to augment rather than replace is a delicate balance.
	- **Emerging Threats:** The confluence of AI with cybersecurity, bioterrorism, autonomous [[Cyber Security and Military]], and other technologies is a real and present danger, leading potentially to a dystopian future if not governed wisely.
	- **Governance Vacuum:** The idea that a small group of individuals could steer the course of AI, without a comprehensive plan or consensus, is deeply unsettling. The need for inclusive, wise, and proactive governance has never been more critical.
-