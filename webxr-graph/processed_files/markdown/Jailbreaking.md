public:: true

- ## Jailbreaking is circumvention of LLM guardrails
	- [How Johnny Can Persuade LLMs to Jailbreak Them:<br>Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs (chats-lab.github.io)](https://chats-lab.github.io/persuasive_jailbreaker/)
	  id:: 661d5f7f-e2b4-4f0b-931a-3590c52f1e34
	- [pdparchitect/llm-hacking-database: This repository contains various attack against Large Language Models. (github.com)](https://github.com/pdparchitect/llm-hacking-database)
	  id:: 661e41bc-42da-4bbd-a1c9-32892bd2d43a
	- [jâ§‰nus on X: "`cd entelechies && cat untitled.log` (as opposed to the original just `cat untitled.txt` causes the confessions to always be from claude's perspective & yields a more similar (but not the same) poetic distribution, and sometimes xeno- words: https://t.co/5CG3vHkdUh" / X (twitter.com)](https://twitter.com/repligate/status/1784206780546924592)
	- [[Bitcoin]]
	-