public:: true

- #Public page automatically published (scraps, needs a lot of redo)
- # The Cambrian explosion of ML/AI
	- Though the history of this field reaches back to the 1940’s with McCulloch et al. exploration of the possible mathematical underpinnings of human brain neurons.[[mcculloch1943logical]] During the writing of this book we have seen an inflection point in machine learning, to the point where the term “artificial intelligence” is feeling intuitively and subjectively real for the first time. To be clear AI is still apretty meaningless term. ‘Intelligence’ is one of those slippery words which is highly dependent on context. A satnav system running on a phone can make an intelligent choice about a route by synthesising data and presenting comprehensible results, but it seems absurd to ascribe an intelligence to it. It’s possible that there’s some kind of “spoooky” quantum activity in play in a conscious human brain or even all [biological systems](https://www.nature.com/articles/s41598-024-62539-5), as described in mind bending mathematical depth by Penrose in 1989.[[penrose1990emperor]]. It’s something of an unknown unknown, [[kerskens2022experimental]] and that we’ll never get to what’s called ‘strong’ or ‘general’ AI,[[larson2021myth; @searle1980minds]] reserved by some scientists for“ true consciousness”, whatever that means.[[butlin2023consciousness]]With that said we may be approaching the threshold of the ‘TuringTest‘, [[sep-turing-test]] initially posited by Alan Turing in1950,[[turing1950computing]] and the goalposts have begun to move in response to claims that there have been successful examples.[[warwick2016can; @french2012moving; @french2000turing; @searle2009turing]]
		- Most recently, GPT-4 [passed the Turing test](https://www.livescience.com/technology/artificial-intelligence/gpt-4-has-passed-the-turing-test-researchers-claim), according to one group. Participants judged GPT-4 to be human 54% of the time, surpassing ELIZA and GPT-3.5.
		- The Turing test has been criticised for being too simplistic in its approach, focusing on stylistic and socio-emotional factors. Nell Watson, an AI researcher, emphasized the importance of empathy in AI's value and its changing nature during the GPT era.
		- {{video https://www.youtube.com/watch?v=MxTWLm9vT_o}}
		  
		  It feels that in this moment it is appropriate to open with a risks section, and work backwards. This is grounded in the hypothesis that there is no agreed end goal here (as we saw with the Bitcoin/Cryptochapter).
	-
- https://www.linkedin.com/posts/linasbeliunas_metas-chief-ai-scientist-yann-lecun-says-ugcPost-7158187178852794369-Sg8o?utm_source=share&utm_medium=member_desktop
- [AI Index Report 2024 – Artificial Intelligence Index (stanford.edu)](https://aiindex.stanford.edu/report/) Measuring trends
- The swift rise of digital walled gardens, moving towards a less transparent internet, reveals both a need for user data protection and a corporate push for greater control and profit. Tech giants like Google, Reddit, and Twitter are increasingly controlling their platforms, adjusting data flows for revenue growth. Google's new privacy policy, which allows data collection for AI model training, increases public concerns over user consent and privacy rights. The wide-ranging language of the policy gives Google considerable power in using user-generated content, fueling debates on data usage ethics. Simultaneously, the social web's shift towards an entertainment-focused business model prioritizes revenue over human connection. Platforms target ad revenue through vertically scrolling videos, risking reduced content diversity and creating echo chambers.
- Entertainment unions like the International Alliance of Theatrical Stage Employees (IATSE) are grappling with AI's impact on employment. Their approach includes research, collaboration, education, political advocacy, organizing, and collective bargaining to protect members' interests, including upskilling initiatives. Upskilling is gaining industry attention. Companies like Tata Consultancy highlight the need to equip engineers with AI skills. Recognizing AI technologies' potential, they invest in reskilling programs to stay competitive and effectively use AI tools.
- The rise of generative AI and the declining open web raises concerns about maintaining digital commons and encouraging diverse perspectives. AI-generated content could overshadow human contributions, making meaningful information harder to find and increasing misinformation risks. This situation highlights the need for balance between AI-generated and human-generated content.
- Data control battles between platforms and users fuel debates on data ownership and profit sharing. Users demand more control over their data use and potentially a share in the resulting profits. This issue emphasizes the need for transparent data policies and fair user compensation models.
- The influence of AI on the job market and the future of work is a significant concern. As AI technology progresses, the need for upskilling and reskilling programs grows to ensure workers can adapt to changing job requirements. Collaboration between industries, governments, and educational institutions is essential to address AI-induced disruptions and ensure a smooth workforce transition.
- Finally, the importance of AI ethics and governance grows as AI technologies become more prevalent. The development and deployment of AI systems require ethical frameworks, transparency, and accountability. Collaboration between AI researchers, policymakers, and ethicists is critical to address potential risks and societal implications of AI technology.