public:: true
icon:: ⚖️
This is a general purpose linking slide for future [[presentation]]

- ## [[Politics, Law, Privacy]]
	- EU AI act is it'll be near impossible now for small disruptive companies to train foundation models because of the administration overhead. Win for America.
	- Governments can now use real-time biometric surveillance in public spaces in prevention of genuine, present, or foreseeable threats, and searches for people suspected of the most serious crimes, so basically everything.
		- "Real-time’ remote biometric identification (RBI) in publicly accessible spaces is prohibited for law enforcement, except when: searching for missing persons, abduction victims, and people who have been human trafficked or sexually exploited; preventing substantial and imminent threat to life, or foreseeable terrorist attack; or identifying suspects in serious crimes (e.g., murder, rape, armed robbery, narcotic and illegal weapons trafficking, organised crime, and environmental crime, etc.)."
	- That will include gait analysis BTW. Europeans just took a big privacy hit. All your personal data goes to the USA, all your private movements go to Interpol (five eyes, eight eyes)
	- Already there are some 3000 constantly updated data point about all users of the internet. This is routinely bought and sold. According to Fowler at the Washington Post by the time a child with a phone is 13 there may be 72 million data points on them, and it's supposed to be illegal to track children
	- Politicians, law enforcement, and private companies have various constraints and restraints based on jurisdiction, but even strong laws like GDPR are routinely (always) ignored through technologies like browser fingerprinting.
		- [Cover Your Tracks (eff.org)](https://coveryourtracks.eff.org/)
		- [CreepJS (abrahamjuliot.github.io)](https://abrahamjuliot.github.io/creepjs/)
	- ![1715109606571.jpeg](../assets/1715109606571_1715110469719_0.jpeg)
	- logseq://graph/ResearchPapers?block-id=656c99ec-9ee4-46f5-bbf2-33f54f2090d9
	- As we have seen in the overturning of the USA abortion ban, the law can change, leaving individuals vulnerable to external forces. Googles promise to delete sensitive data in this case was not carried out. This is their business model and they are not our friends. Police went through 24GB of data from companies with key private chats provided by Meta in order to prosecute a 17 year old girl.
		- [The Hidden-Pregnancy Experiment | The New Yorker](https://www.newyorker.com/culture/the-weekend-essay/the-hidden-pregnancy-experiment)
	- ![image.png](../assets/image_1701614102581_0.png){:width 600}
-
- ## Legal Access
	- [Justice John Roberts 2023 end of year report)](https://www.supremecourt.gov/publicinfo/year-end/2023year-endreport.pdf)
		- And now we face the latest technological frontier: artificial intelligence (AI). At its core, AI combines algorithms and enormous data sets to solve problems. Its many forms and applications include the facial recognition we use to unlock our smart phones and the voice recognition we use to direct our smart televisions. Law professors report with both awe and angst that AI apparently can earn Bs on law school assignments and even pass the bar exam. Legal research may soon be unimaginable without it. AI obviously has great potential to dramatically increase access to key information for lawyers and non-lawyers alike. But just as obviously it risks invading privacy interests and dehumanizing the law.
		- Proponents of AI tout its potential to increase access to justice, particularly for litigants with limited resources. Our court system has a monopoly on many forms of relief. If you want a discharge in bankruptcy, for example, you must see a federal judge. For those who cannot afford a lawyer, AI can help. It drives new, highly accessible tools that provide answers to basic questions, including where to find templates and court forms, how to fill them out, and where to bring them for presentation to the judge—all without leaving home. These tools have the welcome potential to smooth out any mismatch between available resources and urgent needs in our court system.
		- But any use of AI requires caution and humility. One of AI's prominent applications made headlines this year for a shortcoming known as "hallucination," which caused the lawyers using the application to submit briefs with citations to non-existent cases. (Always a bad idea.) Some legal scholars have raised concerns about whether entering confidential information into an AI tool might compromise later attempts to invoke legal privileges. In criminal cases, the use of AI in assessing flight risk, recidivism, and other largely discretionary decisions that involve predictions has generated concerns about due process, reliability, and potential bias. At least at present, studies show a persistent public perception of a "human-AI fairness gap," reflecting the view that human adjudications, for all of their flaws, are fairer than whatever the machine spits out.
		- Many professional tennis tournaments, including the US Open, have replaced line judges with optical technology to determine whether 130 mile per hour serves are in or out. These decisions involve precision to the millimeter. And there is no discretion; the ball either did or did not hit the line. By contrast, legal determinations often involve gray areas that still require application of human judgment.
		- Machines cannot fully replace key actors in court. Judges, for example, measure the sincerity of a defendant's allocution at sentencing. Nuance matters: Much can turn on a shaking hand, a quivering voice, a change of inflection, a bead of sweat, a moment's hesitation, a fleeting break in eye contact. And most people still trust humans more than machines to perceive and draw the right inferences from these clues.
		- Appellate judges, too, perform quintessentially human functions. Many appellate decisions turn on whether a lower court has abused its discretion, a standard that by its nature involves fact-specific gray areas. Others focus on open questions about how the law should develop in new areas. AI is based largely on existing information, which can inform but not make such decisions.
		- Rule 1 of the Federal Rules of Civil Procedure directs the parties and the courts to seek the "just, speedy, and inexpensive" resolution of cases. Many AI applications indisputably assist the judicial system in advancing those goals. As AI evolves, courts will need to consider its proper uses in litigation. In the federal courts, several Judicial Conference Committees—including those dealing with court administration and case management, cybersecurity, and the rules of practice and procedure, to name just a few—will be involved in that effort. I am glad that they will be.
		- I predict that human judges will be around for a while. But with equal confidence I predict that judicial work—particularly at the trial level—will be significantly affected by AI. Those changes will involve not only how judges go about doing their job, but also how they understand the role that AI plays in the cases that come before them.
	- #### Margaret Hagan’s Work on Access to Law through AI
		- **Executive Director of the Legal Design Lab**
			- Focuses on making legal services more user-friendly and engaging through design.
			- Launched the Program for Legal Tech & Design at Stanford’s d.school.
		- **Teaching and Workshops**
			- Teaches project-based classes at Stanford Law School.
			- Leads workshops on the design process for legal professionals.
		- **Research and Publications**
			- Explores how AI can improve access to legal help.
			- Advocates for human-centered design in legal tech.
		- #### AI & Legal Help Initiatives
		- **Policy Practicum: AI For Legal Help**
			- [Envisions AI’s role in the legal sector from a community perspective](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582745)[1](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582745).
		- **Community-Led System Design Practice**
			- Involves community members in the design of AI legal services.
		- #### Events and Panels
		- **AI & Access to Justice Initiative**
		- [Discusses generative AI in new service and business models for legal problems](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582745)[2](https://justiceinnovation.law.stanford.edu/projects/ai-access-to-justice/).
		- **American Academy Event on AI & Equitable Access to Legal Services**
		- [Panelist at a national event discussing AI’s implications for equitable legal services](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582745)[3](https://justiceinnovation.law.stanford.edu/american-academy-event-on-ai-equitable-access-to-legal-services/).
		   
		   For more detailed information on her research and publications, you can visit her [Stanford Law School profile](https://law.stanford.edu/margaret-hagan/) and the [Legal Design Lab website](https://justiceinnovation.law.stanford.edu/american-academy-event-on-ai-equitable-access-to-legal-services/). Her work continues to push the boundaries of how AI can be leveraged to enhance the accessibility and effectiveness of legal services.
- ## Crime
	- AI is already starting to be used in crime detection, crime prediction, and the data brokered by these tech behemoths is already making mistakes. [My chilling run-in with secretive facial-recognition app Clearview AI (telegraph.co.uk)](https://www.telegraph.co.uk/books/non-fiction/clearview-ai-facial-recognition-app-chilling/)
	- As AI increasingly bakes in these data points into ever larger scraped datasets it will be impossible to unwind one's personal history.
	- This too will increasingly be done by AI. We are trending toward AI fighting with AI over your data and the minutiae of your history in ever changing local and global political environments
	- People are concerned about this. There are already apps to semi automate data deletion online. The collapse in [[Trust and Safety]] since the 1970s is clearly documented across governments, media, and big business, but curiously people are trusting both their online social in groups, and machines that act human "enough" far more.  Recently, for unknown reasons they have also started to [[Trust and Safety]] "business" more. logseq://graph/ResearchPapers?block-id=656c9724-f862-4f4e-9a88-75b8b3f1b4e7
	-
-
- # Global politics
- ### 4.12 Artificial Intelligence in a global context
  This currently borrows heavily from [the AI breakdown podcast](https://www.youtube.com/watch?v=5clOHBo8HP8), is an AI generated placeholder, and needs considerably more more.
- #### 4.12.1 Perception of AI and Society
  The examination of AI's implications on societal structures should undoubtedly receive the necessary attention. Soros's language and perception of reality seem particularly interesting, especially in the era of AI. He emphasizes his belief in reality and its importance in providing moral guidance, a concept that seems increasingly challenged in the age of AI.
- #### 4.12.2 AI, Propaganda, and Authoritarianism
  In an opinion piece for The Hill by Bill Drexel and Caleb Withers, titled \"Generative AI could be an authoritarian breakthrough in brainwashing,\" the authors argue that the concern isn't just external attempts to influence U.S. elections, but the impact on the populations within authoritarian countries. They posit that foreign disinformation efforts by Chinese and Russian entities are only the tip of the iceberg, with Beijing and Moscow disseminating massive amounts of propaganda to their own populations. The authors also cite instances of AI-enabled propaganda and misinformation campaigns, both in the context of undermining democracies and consolidating control within authoritarian states.
- #### 4.12.3 Increased Surveillance Through AI
  Another critical concern around AI and authoritarianism is the potential for increased surveillance. With the integration of AI and data scraping techniques, governments can employ extensive teams to facilitate unprecedented levels of surveillance, compromising privacy. Such concerns are raised in the works of authors like Daniel Oberhaus, who posits that authoritarian regimes may have an advantage in AI due to their willingness to exploit data, such as advanced facial recognition data, in ways that open societies might not.
- #### 4.12.4 Worker Surveillance and Remote Work
  Furthermore, the issue of worker surveillance, especially with the rise of remote work regimes, has garnered the attention of various entities, including the White House. This is due to concerns over automated systems that employers are using to monitor their remote workers, highlighting a less benign context of surveillance.
- #### 4.12.5 AI and Ideology
  One way AI might foster authoritarianism is by supporting the ideology of closed societies or authoritarian regimes, such as China. These societies may leverage their global influence to disseminate their particular AI model, aligning it with their motivations and goals. The Carnegie Endowment for International Peace points out that for most countries, AI technology is viewed as an economic development factor that determines their standing in the global technology race, rather than as an ideological preference.
- #### 4.12.6 AI and Central Planning
  Another concern is the fear that AI will make centrally planned economies seem viable, where past attempts failed due to the lack of data. This idea was discussed in a conversation between Peter Thiel and Reed Hoffman hosted by Neil Ferguson at Stanford in 2018. Thiel posited that AI appears to favor centralization, an aspect that supports the principles of central planning.
- #### 4.12.7 Uncontrolled AGI Creation
  On the other hand, some suggest that capitalist competition could result in the creation of AGI that cannot be controlled. Dr. Jeffrey Hinton, a vocal advocate of this view, argues that AI's potential to disrupt business models could drive companies to recklessly pursue advancements in AI to stay competitive. This could lead to increased state power as people become more reliant on the state in an AI-dominated economy, potentially resulting in increased authoritarianism.
- #### 4.12.8 AI Promoting Freedom
  However, AI could also promote freedom in several ways. For instance, AI tools like Altana have been used to identify goods made using forced labor, helping companies make informed supply chain decisions. AI could also serve as a new interface for disseminating information, such as a chatbot that aids detainees in requesting legal assistance.
- #### 4.12.9 AI, Integrity, and Accessibility
  Yet, for AI to achieve its full potential in promoting freedom, the integrity of the information it disseminates must be uncompromised, and its accessibility must be ensured despite potential firewalls.
- #### 4.12.10 AI's Impact on Societal Organization
  Given these diverse viewpoints, it seems that the potential of AI to either aid authoritarianism or promote freedom is yet to be fully explored. However, the inherent ability of democracies to encourage disagreement and diverse perspectives may serve as a counterbalance to the potential of AI for authoritarian control. Moreover, AI's capacity as a catalytic force in societal organization should not be underestimated. The increasing discourse around AI and its implications for labor and technology usage suggests that AI technology is reshaping the world in ways that were unimaginable just a few years ago. Its capabilities in data analysis, decision making, and automation are transforming industries and redefining the scope of what's possible.
- #### 4.12.11 Democratization of AI Technology
  An argument often made in favor of democratization of AI technology is that it should be made open-source and freely available, thus creating a challenging framework for global political incumbents. This perspective is grounded on the belief that technology
	- and its underlying power
	- must be accessible to everyone to mitigate the risks of misuse and ensure fair benefits distribution.
- #### 4.12.12 Open-source AI and Innovation
  Open-source AI can be a vehicle for widespread innovation. It can spur creativity, leading to breakthroughs in various sectors, from healthcare and education to energy and transportation. Open-source technologies facilitate collaboration, accelerate the pace of research, and democratize access, enabling researchers and developers across the globe to contribute to the expansion of AI's capabilities. It opens the possibility for rapid iteration and innovation, reducing the likelihood that a few powerful entities monopolize control over these transformative technologies.
- #### 4.12.13 Open-source AI and Global Politics
  However, as beneficial as open-source AI may appear, the complexity of global politics can make the transition challenging. A landscape where AI technologies are open-source and freely available brings about potential dilemmas in various areas including national security, economic competitiveness, intellectual property rights, and data privacy.
- #### 4.12.14 National Security and Open-source AI
  To start, national security is a primary concern. AI has a myriad of applications in defense and security sectors, many of which could potentially be exploited by adversarial entities. As such, unrestricted access to AI technologies could pose a risk to nations' security. Nevertheless, it is crucial to note that security risks also stem from concentrated AI power. A handful of nations or corporations owning the majority of AI developments may lead to destabilization, power imbalance, and heightened global tensions.
- #### 4.12.15 Economic Competitiveness and Open-source AI
  Economic competitiveness is another intricate aspect. Countries and corporations are engaged in a fiercely competitive race to advance in AI technologies, recognizing the economic gains and strategic advantages tied to AI leadership. Open-source AI might challenge this dynamic, disrupting traditional models of competition. However, it could also create an environment of shared growth, leading to a more balanced global AI landscape.
- #### 4.12.16 Intellectual Property Rights and Open-source AI
  Intellectual property rights form another complex dimension in the discussion. Open-source AI challenges traditional notions of ownership and patents, potentially undermining the incentives for companies and individuals to invest in AI research and development. Balancing the need for innovation with the necessity to protect inventors' rights becomes critical in an open-source framework.
- #### 4.12.17 Data Privacy and Open-source AI
  Data privacy is a further point of contention. Open-source AI, coupled with increasingly ubiquitous data collection methods, raises concerns about individuals' privacy. However, it also provides an opportunity to develop robust, decentralized, and transparent AI systems that respect user privacy.
- #### 4.12.18 A New Social Contract for AI
  Thus, navigating the intersection of AI and global politics necessitates careful consideration. It requires establishing a new social contract for AI---one that respects human rights, promotes equitable economic growth, and protects national security.
- #### 4.12.19 Conclusion
  In conclusion, making AI open-source and freely available represents a shift from the status quo, with both promising potentials and daunting challenges. A global AI framework that upholds democratic principles and values, promotes shared prosperity, and safeguards security and privacy is the aspiration. To achieve this, an inclusive and multidimensional discourse is essential, involving governments, corporations, civil society, academia, and individual citizens. It is through this collective effort that AI's true potential can be harnessed for the global good.
  There is skepticism the idea of artificial general intelligence (AGI) leading to superintelligent machines that threaten humanity in the near future. This supposed risk of AGI is described as a \"red herring\"
	- an unfounded fear. The reasons given are:
	  We do not have a clear understanding or definition of general     intelligence or consciousness.     Current AI like large language models are limited in scope. They are     good at statistical pattern matching in language, not generally     intelligent.     The hypothesis that intelligence and consciousness emerge simply     from increasing computational power is unproven. There are likely     other components we don't understand.
	  The real risk is perhaps government control and regulation of AI development and applications, justified by arguing it is needed for safety and responsible AI. This could impose limits on acceptable speech and thought. Centralised entities could become gatekeepers for how people access and interpret information about the world. Mandating allowable language could narrow ideas and speech to fit an official narrative. Fears of AGI, even if exaggerated, open the door for regulators and bureaucrats to intervene in the name of safety. The risk is not AGI itself but the government control that hype about it enables.
	  There is speculation that AI will automate many white collar cognitive jobs, similar to how industrial machinery automated manual labor. This may \"chase humans up the value stack\" as lower value work is handled by AI, freeing people to focus on higher value creative activities. [\\chapterimage] orange7.jpg
- [He Wanted Privacy. His College Gave Him None – The Markup](https://themarkup.org/machine-learning/2023/11/30/he-wanted-privacy-his-college-gave-him-none)
- [AI security considerations](https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-ai-and-data-protection/how-should-we-assess-security-and-data-minimisation-in-ai/)
- [Sci-fi becomes real as renowned magazine closes submissions due to AI writers: Clarkesworld wrestles with flood of machine-made submissions—over 500 in Feb. alone.](https://arstechnica.com/information-technology/2023/02/sci-fi-becomes-real-as-renowned-magazine-closes-submissions-due-to-ai-writers/)
- The text discusses how a renowned magazine has had to close submissions due to the increasing number of AI writers. It is noted that the AI writers are becoming increasingly skilled and are starting to produce work that is on par with human writers.
- [Lesswrong AI section](https://www.lesswrong.com/tag/ai)
- [Goldman Sachs Predicts 300 Million Jobs Will Be Lost Or Degraded By Artificial Intelligence: Goldman Sachs maintains that if generative AI lives up to its hype, the workforce in the United States and Europe will be upended. The bank estimates 300 million jobs could be lost or diminished due to this fast-growing technology.](https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=3af7314e782b)
- [Medium listing approachs](https://blog.medium.com/how-were-approaching-ai-generated-writing-on-medium-16ee8cb3bc89)
- [Drives us mad, Guardian](https://www.theguardian.com/technology/2023/mar/23/tech-guru-jaron-lanier-the-danger-isnt-that-ai-destroys-us-its-that-it-drives-us-insane)
- [Chatbots must disclose sources or face ban](https://www.artisana.ai/articles/eus-ai-act-stricter-rules-for-chatbots-on-the-horizon)
- [Google and EU private deal](https://techcrunch.com/2023/05/24/eu-google-ai-pact/)
- [How to structure an ML business](https://txt.cohere.com/ai-is-eating-the-world/)
- [Bias investigation](https://www.linkedin.com/feed/update/urn:li:activity:7072912582923173888/)
- [GCHQ warning](https://www.ncsc.gov.uk/blog-post/chatgpt-and-large-language-models-whats-the-risk)
- [confusion matrices](https://en.wikipedia.org/wiki/Confusion_matrix)
- [KTN bridgeai report](https://iuk.ktn-uk.org/wp-content/uploads/2023/10/responsible-trustworthy-ai-report.pdf)
- [Custom GPT open source semantic lock](https://github.com/infotrix/SSLLMs---Semantic-Secuirty-for-LLM-GPTs/blob/master/GPT_Semantic_Security_Template.txt)
- Bitcoin and digital assets
	- A Law Commission consultation on “digital assets” has proposed a new third category of property:
		- it is composed of data represented in an electronic medium, including in the form of computer code, electronic, digital or analogue signals;
		- it exists independently of persons and exists independently of the legal system;
		- it is rivalrous such that use by one prejudices the ability of others;
	- Consensus seems to be that this is a thorough paper, and demonstrates strong knowledge of digital assets by the authors. 
	  Gartner’s hype cycle 2022 features Web3, distributed identity, NFTs, and Metaverse and can be seen in Figure 1.6.
	- The legislative landscape in the UK is comparatively strict with questionable “know your customer / anti money laundering” (KYC/AML) data collection mandated in law. Users of UK exchanges must provide a great deal of personal financial information, and undertake to prove that the wallets they are withdrawing to are their own. From the perspective of the UK SME it seems this seriously limits the potential audience for new products. Europe meanwhile has recently voted through even more restrictive regulation, applying the “transfer of funds regulation” to all transactions coming out of exchanges, enforcing a database of all addresses between companies, and reporting transactions above 1000 Euros to authorities. They have narrowly avoided enforcing KYC on all transfers to private wallets, but have capped transactions at 1000 Euros. The recent “Markets in Crypto Assets (MiCA) legislation imposes overheads that may make it harder for smaller businesses in the sector to operate within the EU, but is has been cautiously welcomed by established players (Figure 2.5, who have been hungry for clarity. It is certainly far short of the ‘ban’ seen in China, and the regulation be enforcement in the USA.
		- European Parliament approved EU’s crypto assets framework, MiCA
		- Enforcement clock starts in June, with 12-18 months for rules to kick in
		- MiCA offers license tailored to crypto asset services and stablecoin issuers
		- Regulation refrains from covering decentralized finance or non-fungible tokens
		- Stablecoin issuer rules boost consumer confidence, potentially increas­ing institutional comfort
- Politics, law, and change
- [WEF risks report links](https://sociable.co/government-and-policy/wef-global-risks-report-cyber-pandemic-erosion-trust-social-cohesion/)
- Regulation (everything)
- Crypto
- [UK](https://www.gov.uk/government/news/uk-sets-out-plans-to-regulate-crypto-and-protect-consumers)
- [GPTs are GPTs: An Early Look at the Labor Market Impact](https://arxiv.org/abs/2303.10130)
- The text discusses the potential implications of Generative Pre-trained Transformer (GPT) models on the U.S. labor market. It uses a new rubric to assess occupations based on their correspondence with GPT capabilities, incorporating both human expertise and classifications from GPT-4. The findings indicate that approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of GPTs, while around 19% of workers may see at least 50% of their tasks impacted. The influence spans all wage levels, with higher-income jobs potentially facing greater exposure. Notably, the impact is not limited to industries with higher recent productivity growth. The text concludes that Generative Pre-trained Transformers exhibit characteristics of general-purpose technologies (GPTs), suggesting that these models could have notable economic, social, and policy implications.
- [El Salvador: Staff Concluding Statement of the 2023 Article IV Mission (other)](https://www.imf.org/en/News/Articles/2023/02/10/el-salvador-staff-concluding-statement-of-the-2023-article-iv-mission)
- Other. The text describes a study by the University of Cambridge which found that people tend to trust robots more when they look and behave like humans.
- [Silvergate Purchases Blockchain libre](https://ir.silvergate.com/news/news-details/2022/Silvergate-Purchases-Blockchain-Payment-Network-Assets-from-Diem/default.aspx)
- The text discusses Silvergate's recent purchase of blockchain payment network assets from Diemwindow.
- [Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users: The startup promises a fairly-distributed, cryptocurrency-based universal basic income. So far all it's done is build a biometric database from the bodies of the poor.](https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/)
- Worldcoin, a cryptocurrency startup, recruited its first 500,000 users by offering them free cash. The company has been accused of deception and exploiting workers, and is now under investigation.
- [Privacy law book](https://www.smashingmagazine.com/printed-books/understanding-privacy/#bookTOC)
- [Online safety bill heather articles](https://webdevlaw.uk/2022/11/21/a-quick-hypothetical-situation-or-your-crash-introduction-to-the-real-world/)
- [Techcrunch on borderless payments](https://techcrunch.com/2021/12/21/borderless-crypto-networks-wrestle-with-state-sanction-compliance/?)
- [Norway takes a stance against Google Analytics](https://www.simpleanalytics.com/blog/norway-takes-a-stance-against-google-analytics)
- [Social Media Is Changing, And Paid Accounts Are The Response](https://www.bigtechnology.com/p/social-media-is-changing-and-paid)
- [Linkedin post by Barry Scanell on EU AI law](https://www.linkedin.com/posts/activity-7062324196256735232-FfEz/?utm_source=share&utm_medium=member_desktop)
- [wikipedia and the child protection bill](https://www.msn.com/en-gb/news/uknews/wikipedia-could-be-taken-offline-in-the-uk/ar-AA1atf9O)
- [Kids are damaged by mobile phones](https://sapienlabs.org/wp-content/uploads/2023/05/Sapien-Labs-Age-of-First-Smartphone-and-Mental-Wellbeing-Outcomes.pdf?utm_source=substack&utm_medium=email)
- [surveillance-capitalism-is-undermining-democracy](https://news.harvard.edu/gazette/story/2019/03/harvard-professor-says-surveillance-capitalism-is-undermining-democracy/)
- https://bitcoinmagazine.com/culture/how-bitcoin-can-save-political-dissidents-in-myanmar
- EU AI ACT
	- [Artificial Intelligence – Q&As (europa.eu)](https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683)
	- The Commission points out that the inception of the AI Act is rooted in the necessity to balance the benefits of AI, such as improved medical care and [[Education and AI]], with the need to mitigate inherent risks.
	- One of the key aspects of the AI Act identified by the Commission is its broad applicability. It encompasses both public and private entities within and outside the EU, as long as the AI system is marketed in the EU or affects individuals within it. This includes AI system providers, deployers, and importers. The Act also covers developers of general-purpose AI models, which are becoming integral to numerous AI systems and hence too significant to remain unregulated.
	- Certain AI systems are identified as high-risk, particularly those impacting safety or fundamental rights in sectors such as healthcare, education, and law enforcement. The Act also identifies AI practices that pose unacceptable risks, contravening EU values, including certain forms of social scoring and real-time remote biometric identification, which are banned. Additionally, systems like chatbots, which pose specific transparency risks, require clear user awareness of their interaction with a machine.
	- For high-risk AI systems, a conformity assessment is required before market introduction, ensuring compliance with standards for trustworthy AI, such as data quality, documentation, transparency, and human oversight. Post-market, these systems must undergo continuous risk management and incident reporting. The Act also imposes specific obligations on providers of general-purpose AI models, especially those with systemic risks, like large generative AI models trained using extensive computational power. These providers must disclose certain information to downstream system providers, respect [[copyright]] law during model training, and engage with the European AI Office to develop Codes of Conduct.
	- The European AI Office and the European Artificial Intelligence Board, supported by an Advisory Forum and a Scientific Panel of independent experts, are designed to ensure a harmonised and effective implementation of the Act across the EU.
	- The Act also stipulates substantial fines for non-compliance, indicating the seriousness with which the EU views AI regulation. Penalties can reach up to €35 million or 7% of the total worldwide annual turnover, depending on the nature of the infringement.
	- The Act mandates that high-risk systems must be trained and tested with representative datasets to minimise biases and must be traceable and auditable. Deployers of high-risk AI systems are required to conduct a fundamental rights impact assessment, ensuring that AI applications comply with fundamental rights legislation and do not exacerbate existing structural discriminations.
-
-
-
-
-
-
- [[pol]]
- [Serious New Warning As Google AI Targets Billions Of Private Messages (forbes.com)](https://www.forbes.com/sites/zakdoffman/2024/01/28/new-details-free-ai-upgrade-for-google-and-samsung-android-users-leaks/)
-